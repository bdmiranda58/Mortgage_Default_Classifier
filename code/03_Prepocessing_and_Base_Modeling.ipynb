{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img style=\"float: left;\" src=\"../images/fanniemae.png\">\n",
    "<br><br><br><br><br><br>\n",
    "______"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mortgage Loan Default Classifier\n",
    "____________\n",
    "____________"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem Statement:\n",
    "_____________\n",
    "Fannie Mae, or more specifically the Federal National Mortgage Association (FNMA), is a government sponsored entity whose primary goal is to raise home ownership and affordable housing levels.  Fannie Mae attempts to accomplish this in essence by purchasing mortgage loans within certain parameters from mortgage lenders.  In turn, mortgage lenders are provided cash flow to issue additional mortgages.<br>\n",
    "\n",
    "The cause of the Financial Crisis of 2008 can in part be drawn back to the purchase of mortgage loans with an actual probability of default that were higher than assumed.  By creating a classification model that will predict whether a mortgage loan will default based on pre-purchase characteristics, Fannie Mae may better avoid high risk mortgage loans.  The model will be evaluated based on Accuracy and False Negative Rate.  In this particular case, the \"positive\" class will be loans that default therefore, we will seek to minimize the False Negative Rate while maximizing Accuracy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Preprocessing and Modeling\n",
    "_________\n",
    "The proportion of Defaults in this given dataset is approximately 0.309%.  For this model to be successful/useful, it is tasked with the challenge of beating this percentage.  In this specific case, the type of incorrect prediction is very important.  Incorrectly predicting that the loan default results in a lost opportunity of potential revenue.  In contrast, incorrectly predicting that the loan will not default will result in huge losses associated a default in the neighborhood of $50,000 on average*.  This second case is referred to as a false negative.  The model will seek not only to have a high overall accuracy but to minimize the false negative rate as well.  A Logistic Regression will be used as the base model.\n",
    "\n",
    "*/ https://homeguides.sfgate.com/basic-foreclosure-fees-costs-61248.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import necessary packages\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.utils import resample\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>LOAN IDENTIFIER</th>\n",
       "      <th>ORIGINATION CHANNEL</th>\n",
       "      <th>SELLER NAME</th>\n",
       "      <th>ORIGINAL INTEREST RATE</th>\n",
       "      <th>ORIGINAL UPB</th>\n",
       "      <th>ORIGINAL LOAN TERM</th>\n",
       "      <th>ORIGINAL LOAN-TO-VALUE (LTV)</th>\n",
       "      <th>ORIGINAL COMBINED LOAN-TO-VALUE (CLTV)</th>\n",
       "      <th>NUMBER OF BORROWERS</th>\n",
       "      <th>ORIGINAL DEBT TO INCOME RATIO</th>\n",
       "      <th>...</th>\n",
       "      <th>LOAN PURPOSE</th>\n",
       "      <th>PROPERTY TYPE</th>\n",
       "      <th>NUMBER OF UNITS</th>\n",
       "      <th>OCCUPANCY TYPE</th>\n",
       "      <th>PROPERTY STATE</th>\n",
       "      <th>PRODUCT TYPE</th>\n",
       "      <th>RELOCATION MORTGAGE INDICATOR</th>\n",
       "      <th>DEFAULT</th>\n",
       "      <th>MI</th>\n",
       "      <th>MIN CREDIT SCORE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>100000841305</td>\n",
       "      <td>C</td>\n",
       "      <td>CITIMORTGAGE, INC.</td>\n",
       "      <td>4.125</td>\n",
       "      <td>124000</td>\n",
       "      <td>360</td>\n",
       "      <td>79</td>\n",
       "      <td>79.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>...</td>\n",
       "      <td>R</td>\n",
       "      <td>SF</td>\n",
       "      <td>1</td>\n",
       "      <td>P</td>\n",
       "      <td>TX</td>\n",
       "      <td>FRM</td>\n",
       "      <td>N</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>792.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>100001889356</td>\n",
       "      <td>R</td>\n",
       "      <td>OTHER</td>\n",
       "      <td>4.625</td>\n",
       "      <td>115000</td>\n",
       "      <td>240</td>\n",
       "      <td>68</td>\n",
       "      <td>68.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>...</td>\n",
       "      <td>C</td>\n",
       "      <td>SF</td>\n",
       "      <td>1</td>\n",
       "      <td>P</td>\n",
       "      <td>IL</td>\n",
       "      <td>FRM</td>\n",
       "      <td>N</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>705.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>100006453372</td>\n",
       "      <td>C</td>\n",
       "      <td>BANK OF AMERICA, N.A.</td>\n",
       "      <td>4.375</td>\n",
       "      <td>175000</td>\n",
       "      <td>360</td>\n",
       "      <td>52</td>\n",
       "      <td>52.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>...</td>\n",
       "      <td>C</td>\n",
       "      <td>PU</td>\n",
       "      <td>1</td>\n",
       "      <td>S</td>\n",
       "      <td>AZ</td>\n",
       "      <td>FRM</td>\n",
       "      <td>N</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>776.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>100010656545</td>\n",
       "      <td>C</td>\n",
       "      <td>BANK OF AMERICA, N.A.</td>\n",
       "      <td>4.375</td>\n",
       "      <td>365000</td>\n",
       "      <td>360</td>\n",
       "      <td>59</td>\n",
       "      <td>59.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>...</td>\n",
       "      <td>C</td>\n",
       "      <td>PU</td>\n",
       "      <td>1</td>\n",
       "      <td>P</td>\n",
       "      <td>IL</td>\n",
       "      <td>FRM</td>\n",
       "      <td>N</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>797.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>100010758624</td>\n",
       "      <td>R</td>\n",
       "      <td>CITIMORTGAGE, INC.</td>\n",
       "      <td>3.875</td>\n",
       "      <td>69000</td>\n",
       "      <td>120</td>\n",
       "      <td>28</td>\n",
       "      <td>28.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>...</td>\n",
       "      <td>C</td>\n",
       "      <td>SF</td>\n",
       "      <td>1</td>\n",
       "      <td>P</td>\n",
       "      <td>SC</td>\n",
       "      <td>FRM</td>\n",
       "      <td>N</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>785.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   LOAN IDENTIFIER ORIGINATION CHANNEL            SELLER NAME  \\\n",
       "0     100000841305                   C     CITIMORTGAGE, INC.   \n",
       "1     100001889356                   R                  OTHER   \n",
       "2     100006453372                   C  BANK OF AMERICA, N.A.   \n",
       "3     100010656545                   C  BANK OF AMERICA, N.A.   \n",
       "4     100010758624                   R     CITIMORTGAGE, INC.   \n",
       "\n",
       "   ORIGINAL INTEREST RATE  ORIGINAL UPB  ORIGINAL LOAN TERM  \\\n",
       "0                   4.125        124000                 360   \n",
       "1                   4.625        115000                 240   \n",
       "2                   4.375        175000                 360   \n",
       "3                   4.375        365000                 360   \n",
       "4                   3.875         69000                 120   \n",
       "\n",
       "   ORIGINAL LOAN-TO-VALUE (LTV)  ORIGINAL COMBINED LOAN-TO-VALUE (CLTV)  \\\n",
       "0                            79                                    79.0   \n",
       "1                            68                                    68.0   \n",
       "2                            52                                    52.0   \n",
       "3                            59                                    59.0   \n",
       "4                            28                                    28.0   \n",
       "\n",
       "   NUMBER OF BORROWERS  ORIGINAL DEBT TO INCOME RATIO        ...         \\\n",
       "0                  1.0                           28.0        ...          \n",
       "1                  1.0                           34.0        ...          \n",
       "2                  2.0                           29.0        ...          \n",
       "3                  3.0                           40.0        ...          \n",
       "4                  1.0                           32.0        ...          \n",
       "\n",
       "  LOAN PURPOSE PROPERTY TYPE NUMBER OF UNITS  OCCUPANCY TYPE PROPERTY STATE  \\\n",
       "0            R            SF               1               P             TX   \n",
       "1            C            SF               1               P             IL   \n",
       "2            C            PU               1               S             AZ   \n",
       "3            C            PU               1               P             IL   \n",
       "4            C            SF               1               P             SC   \n",
       "\n",
       "  PRODUCT TYPE RELOCATION MORTGAGE INDICATOR DEFAULT   MI  MIN CREDIT SCORE  \n",
       "0          FRM                             N       0  0.0             792.0  \n",
       "1          FRM                             N       0  0.0             705.0  \n",
       "2          FRM                             N       0  0.0             776.0  \n",
       "3          FRM                             N       0  0.0             797.0  \n",
       "4          FRM                             N       0  0.0             785.0  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('../data/complete2011q1.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transform categorical features to binary indicator variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_features = ['ORIGINATION CHANNEL', 'SELLER NAME', 'FIRST TIME HOME BUYER INDICATOR', 'LOAN PURPOSE', \n",
    "                        'PROPERTY TYPE', 'OCCUPANCY TYPE', 'PROPERTY STATE', 'PRODUCT TYPE', 'RELOCATION MORTGAGE INDICATOR']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(504559, 92)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.get_dummies(df, columns=categorical_features, drop_first=True)\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Balance target classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    1561\n",
       "0    1561\n",
       "Name: DEFAULT, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# balance target\n",
    "# split classes\n",
    "df_maj = df[df['DEFAULT'] == 0]\n",
    "df_min = df[df['DEFAULT'] == 1]\n",
    " \n",
    "# downsample majority\n",
    "df_maj_resample = resample(df_maj, \n",
    "                           replace=False,    \n",
    "                           n_samples=df_min.shape[0],\n",
    "                           random_state=42)             \n",
    "\n",
    "# concat downsample and minority\n",
    "df_resample = pd.concat([df_maj_resample, df_min])\n",
    " \n",
    "# display new class counts\n",
    "df_resample['DEFAULT'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create train and test datasets "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train test split\n",
    "X = df_resample.drop(columns=['DEFAULT'])\n",
    "y = df_resample['DEFAULT']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y,\n",
    "                                                    stratify=y,\n",
    "                                                    shuffle=True,\n",
    "                                                    random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scale features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scale features to balance feature weights\n",
    "ss = StandardScaler()\n",
    "ss.fit(X_train, y_train)\n",
    "X_train_sc = ss.transform(X_train)\n",
    "X_test_sc = ss.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Base Logistic Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define custom metrics\n",
    "def false_negative_rate(fn, tp):\n",
    "    return fn/(tp+fn)\n",
    "\n",
    "def accuracy(tn, tp, y_test):\n",
    "    return (tn + tp)/len(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# instantiate Logistic model\n",
    "log = LogisticRegression()\n",
    "log.fit(X_train_sc, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7876975651431012"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# accuracy on train data\n",
    "log.score(X_train_sc, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.7228145 , 0.76709402, 0.77136752, 0.78632479, 0.73504274])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# cross validation accuracy on train data\n",
    "cross_val_score(log, X_train_sc, y_train, cv=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7554417413572343"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# accuracy on test data\n",
    "log.score(X_test_sc, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Insight:__\n",
    "First, the accuracy is of the base logistic classification model leaves a lot to be desired.  The overall test accuracy of 0.72 is very low and the difference between the training and test accuracy scores hints to some overfitting. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[283, 108],\n",
       "       [ 83, 307]], dtype=int64)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# assign predictions\n",
    "preds = log.predict(X_test_sc)\n",
    "\n",
    "# assign outcome cases for use in custom metrics\n",
    "tn, fp, fn, tp = confusion_matrix(y_test, preds).ravel()\n",
    "\n",
    "# display confusion matrix on base threshold of 50%\n",
    "confusion_matrix(y_test, preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.2128205128205128"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# display false negative rate\n",
    "false_negative_rate(fn, tp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Insight:__\n",
    "This base model at a 50% threshold has a false negative rate of 21.3% which is not close to the 0.31% bar set by the overall Default proportion.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>NoDefault</th>\n",
       "      <th>Default</th>\n",
       "      <th>y_pred</th>\n",
       "      <th>y_pred_adj</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.368981</td>\n",
       "      <td>0.631019</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.978883</td>\n",
       "      <td>0.021117</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.517980</td>\n",
       "      <td>0.482020</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.495776</td>\n",
       "      <td>0.504224</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.981273</td>\n",
       "      <td>0.018727</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   NoDefault   Default  y_pred  y_pred_adj\n",
       "0   0.368981  0.631019       1           1\n",
       "1   0.978883  0.021117       0           0\n",
       "2   0.517980  0.482020       0           1\n",
       "3   0.495776  0.504224       1           1\n",
       "4   0.981273  0.018727       0           0"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create prediction table to see affect of adjusted threshold\n",
    "preds_adj = pd.DataFrame(log.predict_proba(X_test_sc), columns=['NoDefault', 'Default'])\n",
    "preds_adj['y_pred'] = preds\n",
    "preds_adj['y_pred_adj'] = preds_adj['Default'].map(lambda x: 1 if x >= .05 else 0)\n",
    "preds_adj.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# assign outcome cases for use in custom metrics given threshold adjustment\n",
    "tn, fp, fn, tp = confusion_matrix(y_test, preds_adj['y_pred_adj']).ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 66, 325],\n",
       "       [  9, 381]], dtype=int64)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# display confusion matrix based on adjusted threshold\n",
    "confusion_matrix(y_test, preds_adj['y_pred_adj'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5723431498079385"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# display accuracy given adjusted threshold\n",
    "accuracy(tn, tp, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.023076923076923078"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# display false negative rate given adjusted threshold\n",
    "false_negative_rate(fn, tp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Insight:__\n",
    "By drastically adjusting the threshold of what would be considered a Default from 50% to 5%, the false negative rate is pushed down to 2.3%.  Unfortunately, this still does not surpass the 0.31% benchmark and it comes at very high expense of Non Default misclassifications."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:dsi]",
   "language": "python",
   "name": "conda-env-dsi-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
